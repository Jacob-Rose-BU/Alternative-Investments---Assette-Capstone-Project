{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacob-Rose-BU/Alternative-Investments---Assette-Capstone-Project/blob/main/Fund_Metadata_OpenRouter_GPT_API_Source.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .gitignore\n",
        "/.env\n",
        "/.venv\n",
        "/__pycache__/\n",
        "/*.pyc\n",
        "/*.pyo\n",
        "/*.pyd\n",
        "/.pytest_cache/\n",
        "/*.log\n",
        "/.mypy_cache/\n",
        "/*.db\n",
        "/.DS_Store\n",
        "# Ignore Python bytecode files\n",
        "*.py[cod]\n",
        "# Ignore Jupyter Notebook checkpoints\n",
        ".ipynb_checkpoints/\n",
        "# Ignore virtual environment directories\n",
        "venv/\n",
        ".env/\n",
        "# Ignore IDE/editor specific files\n",
        ".idea/\n",
        ".vscode/\n",
        "# Ignore coverage reports\n",
        "coverage.xml\n",
        "# Ignore build directories\n",
        "build/\n",
        "dist/\n",
        "# Ignore package distribution files\n",
        "*.egg-info/\n",
        "# Ignore configuration files\n",
        "*.cfg\n",
        "*.ini"
      ],
      "metadata": {
        "id": "14lE0JwpHI9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPT-Generated Synthetic Data\n",
        "This notebook uses the OpenRouter API to generate high-quality synthetic factsheet commentary for investment funds. Currently based on only a fund name and reporting period (month/year), the notebook produces templated narrative sections: fund description, strategy, and manager commentary.\n",
        "\n",
        "The outputs are structured to populate the fund_profile table in Snowflake, providing a content layer that complements quantitative holdings, ESG scores, and performance metrics. These data sources will be integrated into the generation once the API key is fixed and we are able to ensure the original code is clean and works with no errors in generation.  \n",
        "\n",
        "##Execution Instructions\n",
        "To run this notebook:\n",
        "\n",
        "1. Ensure your OpenRouter API key is securely stored as environment variable (api_key)\n",
        "\n",
        "2. Run the notebook top to bottom, confirming that each section runs completely and output is given in the final section\n",
        "\n",
        "3. Edit prompt templates as needed for specific tone or format preferences\n",
        "\n",
        "##File Roadmap\n",
        "1. Define inputs (fund name and reporting month)\n",
        "\n",
        "2. Build AI prompt templates for each narrative section:\n",
        "\n",
        "  * Fund Description\n",
        "\n",
        "  * Strategy Summary\n",
        "\n",
        "  * Monthly Manager Commentary\n",
        "\n",
        "3. Generate text for each section using a structured API call\n",
        "\n",
        "4. Collect results into a standardized output list for downstream storage or processing\n",
        "\n",
        "5. Potential Snowflake implementation to pull stock, performance, and ESG data to refine qualitative outputs. This is on hold until API KEY is verified to work.\n",
        "\n",
        "##Next Steps\n",
        "###GPT API Integration\n",
        "* Improve prompt wording for more consistent tone and structure across fund types\n",
        "\n",
        "* Add support for template frameworks (e.g. f-string-driven prompts)\n",
        "\n",
        "* Validate and screen outputs for safe, compliant phrasing\n",
        "\n",
        "* Wrap generation logic in a reusable function or class for easier integration\n",
        "\n",
        "###Snowflake Integration\n",
        "* Create load_gpt_factsheets.py to push narrative sections into Snowflake\n",
        "\n",
        "* Structure table with keys: fund_id, as_of_month, field_name, content\n",
        "\n",
        "* Align GPT narrative with actual structured fund metadata where available\n",
        "\n",
        "###Enhancements\n",
        "* Enable batch generation for multiple funds and periods\n",
        "\n",
        "* Add logic to feed ESG or performance data into GPT context dynamically\n",
        "\n",
        "* Implement prompt-response logging and versioning for traceability\n",
        "\n",
        "* Extend support to multilingual output (e.g., Spanish, French)"
      ],
      "metadata": {
        "id": "xoL8Eg7LGfe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn2ztlvnDo8G",
        "outputId": "5598b7ae-25c7-40ce-afde-62c68e9230c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJdu8wrWZ8ld",
        "outputId": "e44888ff-9739-4a82-a2d7-6ff996ba27fe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Faker in /usr/local/lib/python3.11/dist-packages (37.4.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from Faker) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import random\n",
        "import string\n",
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from faker import Faker\n",
        "from dotenv import load_dotenv\n",
        "from sqlalchemy import create_engine\n"
      ],
      "metadata": {
        "id": "s4vUK-KASfr7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# ENV VARS\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "sf_user = os.getenv(\"SNOWFLAKE_USER\")\n",
        "sf_password = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
        "sf_account = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
        "sf_warehouse = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
        "sf_database = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
        "sf_schema = os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
        "\n",
        "# REQUIRED COLUMNS from Snowflake/CSV\n",
        "REQUIRED_COLS = [\n",
        "    \"PORTFOLIOCODE\", \"NAME\", \"INVESTMENTSTYLE\", \"PORTFOLIOCATEGORY\",\n",
        "    \"OPENDATE\", \"PERFORMANCEINCEPTIONDATE\", \"TERMINATIONDATE\",\n",
        "    \"BASECURRENCYCODE\", \"BASECURRENCYNAME\", \"ISBEGINOFDAYPERFORMANCE\", \"PRODUCTCODE\"\n",
        "]\n",
        "\n",
        "# ----------- LOAD TABLE FROM SNOWFLAKE -----------\n",
        "def get_snowflake_engine():\n",
        "    return create_engine(\n",
        "        f\"snowflake://{sf_user}:{sf_password}@{sf_account}/{sf_database}/{sf_schema}?warehouse={sf_warehouse}\"\n",
        "    )\n",
        "\n",
        "def load_portfolio_data(source=\"snowflake\", csv_path=None):\n",
        "    if source == \"csv\" and csv_path:\n",
        "        df = pd.read_csv(csv_path)\n",
        "    else:\n",
        "        engine = get_snowflake_engine()\n",
        "        query = \"SELECT * FROM AST_ALTERNATIVES_DB.DBO.PORTFOLIOGENERALINFORMATION\"\n",
        "        df = pd.read_sql(query, engine)\n",
        "\n",
        "    df = df[REQUIRED_COLS]\n",
        "    df = df.dropna(subset=[\"PORTFOLIOCODE\", \"NAME\"])  # Basic check\n",
        "    return df"
      ],
      "metadata": {
        "id": "I-VLSwXDJHDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "HLukdle9rfoU",
        "outputId": "333a681c-5d9f-452e-ecd4-d0489637c8eb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa9a6f1b-2e25-49e3-adeb-c13646cbfbc2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa9a6f1b-2e25-49e3-adeb-c13646cbfbc2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving openrouterkey.env.txt to openrouterkey.env (2).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Get the API key from environment variables\n",
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found. Make sure it's defined in the .env file.\")\n",
        "\n",
        "# url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "# Corrected POST-based API request function\n",
        "def fetch_data_from_api(prompt):\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"HTTP-Referer\": \"https://colab.research.google.com\",  # Must match whitelisted origin\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"mistralai/mistral-7b-instruct\",  # You can change this to any available OpenRouter model\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload, timeout=15)\n",
        "        response.raise_for_status()  # Raises HTTPError for 4xx or 5xx status\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if \"choices\" not in data or not data[\"choices\"]:\n",
        "            raise ValueError(\"No choices returned in API response.\")\n",
        "\n",
        "        return data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        print(f\"HTTP error occurred: {http_err} - Status code: {response.status_code}\")\n",
        "        print(\"Response content:\", response.text)\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        print(f\"Request error: {req_err}\")\n",
        "    except ValueError as ve:\n",
        "        print(f\"Data error: {ve}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "lQAggoUHCptu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_config(config_path=\"config.yaml\"):\n",
        "#     with open(config_path, \"r\") as file:\n",
        "#         return yaml.safe_load(file)\n",
        "\n",
        "# # ---------------------------\n",
        "# # Generate synthetic fund records\n",
        "# # ---------------------------\n",
        "# def random_date(start_year):\n",
        "#     start_date = datetime(start_year, 1, 1)\n",
        "#     end_date = datetime.today()\n",
        "#     return start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "# def generate_fund_id():\n",
        "#     return ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
        "\n",
        "# # portfolio\n",
        "# def generate_funds(config):\n",
        "#     faker = Faker()\n",
        "#     funds = []\n",
        "#     for _ in range(config[\"fund_generation\"][\"num_fund\"]):\n",
        "#         fund = {\n",
        "#             \"fund_id\": generate_fund_id(),\n",
        "#             \"fund_name\": faker.company(),\n",
        "#             \"fund_type\": random.choice(config[\"fund_generation\"][\"fund_types\"]),\n",
        "#             \"strategy\": random.choice(config[\"fund_generation\"][\"strategies\"]),\n",
        "#             \"inception_date\": random_date(config[\"fund_generation\"][\"start_year\"]).strftime(\"%Y-%m-%d\"),\n",
        "#             \"benchmark_code\": random.choice(config[\"fund_generation\"][\"benchmark_codes\"]),\n",
        "#             \"status\": random.choice(config[\"fund_generation\"][\"statuses\"]),\n",
        "#             \"as_of_date\": datetime.today().strftime(\"%Y-%m-%d\")  # Add today's date as as_of_date\n",
        "#         }\n",
        "#         funds.append(fund)\n",
        "#     return pd.DataFrame(funds)"
      ],
      "metadata": {
        "id": "82W7pd1QZkH_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # EXAMPLE\n",
        "# import os\n",
        "# import requests\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv()\n",
        "# api_key = os.getenv(\"API_KEY\")\n",
        "\n",
        "# url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "# headers = {\n",
        "#     \"Authorization\": f\"Bearer {api_key}\",\n",
        "#     \"HTTP-Referer\": \"https://colab.research.google.com\",  # <- THIS MUST MATCH WHITELIST\n",
        "#     \"Content-Type\": \"application/json\"\n",
        "# }\n",
        "\n",
        "# payload = {\n",
        "#     \"model\": \"mistralai/mistral-7b-instruct\",\n",
        "#     \"messages\": [{\"role\": \"user\", \"content\": \"Explain clean energy in one sentence.\"}],\n",
        "#     \"temperature\": 0.7,\n",
        "#     \"max_tokens\": 150\n",
        "# }\n",
        "\n",
        "# try:\n",
        "#     response = requests.post(url, headers=headers, json=payload)\n",
        "#     response.raise_for_status()\n",
        "#     print(\"âœ… Response:\", response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
        "# except requests.exceptions.HTTPError as e:\n",
        "#     print(f\"âŒ HTTP error: {e} - Status Code: {response.status_code}\")\n",
        "#     print(\"ðŸ” Response content:\", response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SELbgFrHEhr",
        "outputId": "8c4ca476-167f-4315-9345-6a5935acbf97"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Response:  Clean energy refers to power sources that are renewable, sustainable, and produce little to no pollution, such as solar, wind, hydro, and geothermal power, as opposed to fossil fuels that deplete naturally and contribute significantly to greenhouse gas emissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fund_description_prompt(fund):\n",
        "    return f\"\"\"\n",
        "Write a concise description for a hypothetical alternatives investment fund named {fund['fund_name']}.\n",
        "The fund was launched in {fund['inception_date']} and is currently {fund['status']}.\n",
        "It follows a {fund['strategy']} strategy and is benchmarked to {fund['benchmark_code']}.\n",
        "The fund focuses on {fund['fund_type'].lower()} investors seeking exposure to sustainable and impact-driven projects.\n",
        "Describe its core investment areas, impact goals, and investor appeal.\n",
        "\"\"\"\n",
        "\n",
        "def create_strategy_prompt(fund):\n",
        "    return f\"\"\"\n",
        "Summarize the investment strategy of the U.S.-based fund named {fund['fund_name']}, launched in {fund['inception_date']}.\n",
        "It employs a {fund['strategy']} approach and focuses on scaling sustainable infrastructure or clean energy in underserved regions.\n",
        "Benchmark reference: {fund['benchmark_code']}.\n",
        "Write in an institutional tone. Limit to 100 words.\n",
        "\"\"\"\n",
        "\n",
        "def create_manager_commentary_prompt(fund):\n",
        "    # Convert as_of_date (YYYY-MM-DD) â†’ \"Month Year\" (e.g., \"May 2024\")\n",
        "    as_of_str = fund.get(\"as_of_date\", \"\")\n",
        "    try:\n",
        "        month_year = datetime.strptime(as_of_str, \"%Y-%m-%d\").strftime(\"%B %Y\")\n",
        "    except Exception:\n",
        "        month_year = \"a recent period\"\n",
        "\n",
        "    return f\"\"\"\n",
        "Provide a professional manager commentary for the fund {fund['fund_name']} for the month of {month_year}.\n",
        "The fund delivered stable returns and impact outcomes aligned with its {fund['strategy']} strategy.\n",
        "Include:\n",
        "- Commentary on clean tech or sustainability themes\n",
        "- A notable challenge or risk\n",
        "- A brief forward-looking perspective on the market\n",
        "Target a concise and polished institutional tone.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BULFZy3tfrmn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- PROMPT GENERATION -----------\n",
        "def create_fund_description_prompt(row):\n",
        "    return f\"\"\"\n",
        "Write a concise description for a hypothetical fund named {row['NAME']}.\n",
        "Launched on {row['OPENDATE']}, this fund is categorized as {row['PORTFOLIOCATEGORY']} with an investment style of {row['INVESTMENTSTYLE']}.\n",
        "It is denominated in {row['BASECURRENCYNAME']} and serves as part of product line {row['PRODUCTCODE']}.\n",
        "Describe its key themes, goals, and investor appeal.\n",
        "\"\"\"\n",
        "\n",
        "def create_strategy_prompt(row):\n",
        "    return f\"\"\"\n",
        "Summarize the investment strategy for the fund {row['NAME']}, opened on {row['OPENDATE']}, classified as {row['PORTFOLIOCATEGORY']} and following a {row['INVESTMENTSTYLE']} style.\n",
        "The fund operates in {row['BASECURRENCYNAME']} and is intended for investors seeking structured long-term outcomes.\n",
        "Use an institutional tone. Keep under 100 words.\n",
        "\"\"\"\n",
        "\n",
        "def create_manager_commentary_prompt(row):\n",
        "    try:\n",
        "        month_year = datetime.today().strftime(\"%B %Y\")\n",
        "    except:\n",
        "        month_year = \"a recent period\"\n",
        "\n",
        "    return f\"\"\"\n",
        "Provide a professional manager commentary for the fund {row['NAME']} for {month_year}.\n",
        "Include:\n",
        "- Commentary on sustainability themes or macro conditions\n",
        "- A notable challenge or performance risk\n",
        "- A forward-looking view\n",
        "Write in a polished institutional tone.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UuP_tdVCJVCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_qualitative_paragraphs(df):\n",
        "    qualitative_rows = []\n",
        "\n",
        "    for _, fund in df.iterrows():\n",
        "        as_of_date = fund.get(\"as_of_date\", \"\")\n",
        "        try:\n",
        "            month_year = datetime.strptime(as_of_date, \"%Y-%m-%d\").strftime(\"%B %Y\")\n",
        "        except:\n",
        "            month_year = \"Unknown\"\n",
        "\n",
        "        desc_prompt = create_fund_description_prompt(fund)\n",
        "        strat_prompt = create_strategy_prompt(fund)\n",
        "        comm_prompt = create_manager_commentary_prompt(fund)\n",
        "\n",
        "        print(f\"ðŸ“ Generating for {fund['fund_name']}\")\n",
        "\n",
        "        fund_description = fetch_data_from_api(desc_prompt)\n",
        "        fund_strategy = fetch_data_from_api(strat_prompt)\n",
        "        fund_commentary = fetch_data_from_api(comm_prompt)\n",
        "\n",
        "        qualitative_rows.append({\n",
        "            **fund,\n",
        "            \"fund_description\": fund_description,\n",
        "            \"fund_strategy\": fund_strategy,\n",
        "            f\"fund_commentary_{month_year}\": fund_commentary\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(qualitative_rows)"
      ],
      "metadata": {
        "id": "GxGQubUVS5nk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- GENERATE PARAGRAPHS -----------\n",
        "def generate_qualitative_for_all(df):\n",
        "    rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        print(f\"ðŸ§  Generating for {row['NAME']}\")\n",
        "\n",
        "        desc = fetch_data_from_api(create_fund_description_prompt(row))\n",
        "        strat = fetch_data_from_api(create_strategy_prompt(row))\n",
        "        comm = fetch_data_from_api(create_manager_commentary_prompt(row))\n",
        "\n",
        "        rows.append({\n",
        "            **row,\n",
        "            \"FUND_DESCRIPTION\": desc,\n",
        "            \"FUND_STRATEGY\": strat,\n",
        "            \"MANAGER_COMMENTARY\": comm\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "4j2JPxGZJpdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- WRITE BACK TO SNOWFLAKE -----------\n",
        "def append_to_snowflake_table(df, table=\"PORTFOLIOGENERALINFORMATION\"):\n",
        "    engine = get_snowflake_engine()\n",
        "    df.to_sql(table, con=engine, if_exists=\"append\", index=False)\n",
        "    print(\"âœ… Appended enriched rows to Snowflake.\")\n",
        "\n",
        "# ----------- MAIN -----------\n",
        "if __name__ == \"__main__\":\n",
        "    portfolio_df = load_portfolio_data(source=\"snowflake\")\n",
        "    enriched_df = generate_qualitative_for_all(portfolio_df)\n",
        "    append_to_snowflake_table(enriched_df)"
      ],
      "metadata": {
        "id": "57gB9iN-Jcp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # config = load_config(\"config.yaml\")\n",
        "    # fund_df = generate_funds(config)\n",
        "    enriched_df = generate_qualitative_paragraphs(fund_df)\n",
        "\n",
        "    enriched_df.to_csv(\"fund_qualitative_outputs.csv\", index=False)\n",
        "    print(\"âœ… Generated qualitative fund data saved to fund_qualitative_outputs.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDc4edYpTEnC",
        "outputId": "38006691-01b5-400e-80a3-9a722754a6bd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Generating for Collins-Gutierrez\n",
            "ðŸ“ Generating for Ray and Sons\n",
            "ðŸ“ Generating for Ramos, Williams and Kennedy\n",
            "ðŸ“ Generating for Wiggins, Wilkerson and Harvey\n",
            "ðŸ“ Generating for Berry, Perry and Carlson\n",
            "ðŸ“ Generating for Blake Inc\n",
            "ðŸ“ Generating for Sanchez LLC\n",
            "ðŸ“ Generating for Bernard, Gillespie and Walker\n",
            "ðŸ“ Generating for Middleton, Acosta and English\n",
            "ðŸ“ Generating for Joseph-Brennan\n",
            "âœ… Generated qualitative fund data saved to fund_qualitative_outputs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Potential Snowflake Implementation with Stock and ESG Data"
      ],
      "metadata": {
        "id": "zmsj1QTtJqLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snowflake-connector-python\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "srxm6ixRFNZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snowflake.connector\n",
        "\n",
        "# Load credentials\n",
        "load_dotenv()\n",
        "\n",
        "sf_user = os.getenv(\"SNOWFLAKE_USER\")\n",
        "sf_password = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
        "sf_account = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
        "sf_database = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
        "sf_schema = os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
        "sf_warehouse = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
        "\n",
        "# Connect to Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=sf_user,\n",
        "    password=sf_password,\n",
        "    account=sf_account,\n",
        "    warehouse=sf_warehouse,\n",
        "    database=sf_database,\n",
        "    schema=sf_schema\n",
        ")\n",
        "\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Function to upload DataFrame\n",
        "def append_to_snowflake(df, table_name):\n",
        "    try:\n",
        "        # Create temp CSV\n",
        "        temp_csv = \"/tmp/temp_fund_upload.csv\"\n",
        "        df.to_csv(temp_csv, index=False)\n",
        "\n",
        "        # Create staging area in memory\n",
        "        cursor.execute(f\"PUT file://{temp_csv} @%{table_name} OVERWRITE = TRUE\")\n",
        "\n",
        "        # Copy from staged CSV to table\n",
        "        columns = \",\".join(df.columns)\n",
        "        cursor.execute(f\"\"\"\n",
        "            COPY INTO {table_name}\n",
        "            FROM @%{table_name}\n",
        "            FILE_FORMAT = (TYPE = CSV FIELD_OPTIONALLY_ENCLOSED_BY='\"' SKIP_HEADER=1)\n",
        "        \"\"\")\n",
        "\n",
        "        print(f\"âœ… Data appended to {table_name} in Snowflake\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"âŒ Failed to upload data:\", e)\n",
        "    finally:\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "\n",
        "# Example usage:\n",
        "append_to_snowflake(enriched_df, \"PORTPORTFOLIOGENERALINFORMATION\")"
      ],
      "metadata": {
        "id": "N5iSNVugFR73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
