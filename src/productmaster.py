# -*- coding: utf-8 -*-
"""PRODUCTMASTER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tuHwnjJyfMWFy7yy3i0GG1VJHHLA4NA7

# PRODUCTMASTER Table – Synthetic Data

The `PRODUCTMASTER` table contains the core metadata for all investment products offered by the firm. Each row represents a distinct fund or product, including key attributes like strategy, legal structure, asset class, and share class. It also includes proxy keys for downstream tracking, such as performance and representative accounts.

Additionally, the table may store qualitative narrative fields (e.g., fund description, strategy, and manager commentary) for factsheet generation. These fields are usually AI-generated based on fund characteristics and are tied to the same primary key (`PRODUCTCODE`). This table serves as a foundational dimension for joining with related tables like holdings, performance, attribution, and factsheet commentary.

---

| **Column Name**           | **Description**                                                                                              |
|---------------------------|--------------------------------------------------------------------------------------------------------------|
| `PRODUCTCODE`             | Unique code for each product. Used as a **primary key** and may appear as a **foreign key** in other tables. |
| `PRODUCTNAME`             | Name of the product fund. Example: "XYZ Growth Opportunities Fund".                                          |
| `STRATEGY`                | Investment strategy associated with the fund (e.g., "Long/Short Equity", "Absolute Return").                 |
| `VEHICLECATEGORY`         | Broad category of the legal vehicle (e.g., "Trust", "LLC", "LP").                                            |
| `VEHICLETYPE`             | Specific legal structure or subtype (e.g., "Delaware LP", "Master-Feeder", "UCITS").                         |
| `ASSETCLASS`              | Primary asset class targeted by the fund (e.g., "Private Equity", "Hedge Fund", "Real Assets").              |
| `SHARECLASS`              | Share class designation (e.g., "Class A", "Institutional", "Retail").                                        |
| `PERFORMANCEACCOUNT`      | Simulated ID for performance tracking. Can be used as a **proxy key** in a performance table.                |
| `REPRESENTATIVEACCOUNT`   | Simulated ID for reporting or marketing ownership. Also a **proxy key** in related commentary tables.        |
| `ISMARKETED`              | Indicates whether the fund is actively marketed to investors (Yes/No).                                       |
| `PARENTPRODUCTCODE`       | Code for the parent or umbrella product (used for hierarchical grouping).                                    |
| `fund_description`        | Narrative summary describing the fund’s focus, goals, and investor appeal. *(AI-generated)*                  |
| `fund_strategy`           | Summary of the fund’s investment strategy and asset focus. *(AI-generated)*                                  |
| `fund_commentary_<Month>` | Manager commentary for a given reporting period (e.g., "fund_commentary_May 2024"). *(AI-generated)*          |

---

**Note:**  
Keys like `PRODUCTCODE` may be reused in related tables (e.g., fund performance, holdings, commentary, attribution) as foreign key proxies.  
The qualitative fields are dynamic and may be refreshed or extended over time as market or fund characteristics change.
"""

!pip install faker

!pip install python-dotenv

import os
import yaml
import random
import string
import pandas as pd
import requests
from datetime import datetime, timedelta
from faker import Faker
from dotenv import load_dotenv
from sqlalchemy import create_engine

# Set up faker and random seed for reproducibility
fake = Faker()
random.seed(42)

# Define how many rows of synthetic data to create
NUM_ROWS = 50

# Define realistic categorical values for each relevant field
strategies = ['Growth Equity', 'Long/Short Equity', 'Direct Lending', 'Renewable Energy']
vehicle_categories = ['LP', 'Feeder', 'Master', 'Offshore']
vehicle_types = ['Delaware LP', 'Cayman SPC', 'UCITS', 'SICAV', 'Trust']
asset_classes = ['Alternatives']
share_classes = ['Class A', 'Class B', 'Institutional', 'Retail', 'Founder']
is_marketed_options = ['Yes', 'No']

# Pre-generate unique product codes to reference in parent-child relationships
base_product_codes = [f"PRD{i:04d}" for i in range(1, NUM_ROWS + 1)]

# Initialize empty list to hold each synthetic row
synthetic_data = []

# Main data generation loop
for i in range(NUM_ROWS):
    product_code = base_product_codes[i]  # Unique key for this row
    strategy = random.choice(strategies)
    product_name = f"{fake.company()} {strategy}"  # Fund-style name
    vehicle_category = random.choice(vehicle_categories)
    vehicle_type = random.choice(vehicle_types)
    asset_class = random.choice(asset_classes)
    share_class = random.choice(share_classes)

    # Proxy keys for use in performance/representative tables
    performance_account = f"PA-{random.randint(1000, 9999)}"
    representative_account = f"RA-{random.randint(1000, 9999)}"
    is_marketed = random.choice(is_marketed_options)

    # Assign a parent product code (cannot be self)
    parent_product_code = random.choice([code for code in base_product_codes if code != product_code])

    # Construct row as dictionary
    synthetic_data.append({
        'PRODUCTCODE': product_code,
        'PRODUCTNAME': product_name,
        'STRATEGY': strategy,
        'VEHICLECATEGORY': vehicle_category,
        'VEHICLETYPE': vehicle_type,
        'ASSETCLASS': asset_class,
        'SHARECLASS': share_class,
        'PERFORMANCEACCOUNT': performance_account,  # can be used as FK in performance table
        'REPRESENTATIVEACCOUNT': representative_account,  # can be FK in rep table
        'ISMARKETED': is_marketed,
        'PARENTPRODUCTCODE': parent_product_code  # simulated hierarchy
    })

# Convert to DataFrame
df_funds = pd.DataFrame(synthetic_data)

# Preview first few rows in Colab
df_funds.head()

# Filter only the required columns for reference in other tables
df_productcode = df_funds[['PRODUCTCODE']] # For use in PORTFOLIOGENERALINFORMATION.ipynb file

# Export to CSV (no index)
df_productcode.to_csv('product_codes.csv', index=False)

"""# GPT-Generated Synthetic Data

This portion of the notebook uses the OpenRouter API to generate high-quality synthetic factsheet commentary for alternative investment funds. It accepts structured fund metadata—such as product code, strategy, vehicle type, and asset class—and produces templated narrative sections: **fund description**, **strategy summary**, and **manager commentary**.

The generated text is intended to populate qualitative fields in the `PRODUCTMASTER` table within Snowflake, complementing numerical holdings, ESG scores, and performance data. Full integration with Snowflake and other data sources is planned after successful testing of the API key and pipeline stability.

---

## Execution Instructions

1. **Ensure your OpenRouter API key** is securely stored in your environment (`OPENROUTER_API_KEY`) or loaded via `.env` using `dotenv`.
2. **Upload your fund metadata file** (e.g., `product_codes.csv`) which contains at least `PRODUCTCODE` and `PRODUCTNAME`.
3. **Run the notebook top to bottom**, ensuring each section executes without error.
4. **Review or customize the GPT prompt templates** if needed for tone, brand alignment, or format.
5. Final enriched outputs will be available as a CSV for download or further pipeline integration.

---

## File Roadmap

1. **Upload Input File**
   - Accept fund metadata including columns such as `PRODUCTCODE`, `PRODUCTNAME`, `STRATEGY`, `ASSETCLASS`, etc.

2. **Define Prompt Templates**
   - Generate fund-specific GPT prompts for:
     - Fund Description
     - Strategy Summary
     - Manager Commentary

3. **Call GPT API**
   - Use the OpenRouter API to generate qualitative text for each fund row.
   - Responses are logged and formatted.

4. **Export Output**
   - All generated narratives are merged back into the original dataset.
   - CSV download is enabled for offline use or QA.

5. **(Coming Soon) Snowflake Integration**
   - Load output directly to Snowflake.
   - Enhance prompt inputs using historical stock, ESG, and performance data via Snowflake queries.
   - This step is paused until the API key is verified and prompt-response logic is finalized.

---
"""

# Upload env file with your API key
from google.colab import files
uploaded = files.upload()

# Rename the file if needed
import os

if os.path.exists("env.txt"):
    os.rename("env.txt", ".env")
    print("Renamed env.txt to .env")
else:
    print("File not found. Make sure you uploaded .env.txt.")

# Load environment variables
load_dotenv()

# Get the API key from environment variables
api_key = os.getenv("OPENROUTER_API_KEY")

if not api_key:
    raise ValueError("API key not found. Make sure it's defined in the .env file.")

# url = "https://openrouter.ai/api/v1/chat/completions"

# Corrected POST-based API request function
def fetch_data_from_api(prompt):
    url = "https://openrouter.ai/api/v1/chat/completions"

    headers = {
        "Authorization": f"Bearer {api_key}",
        "HTTP-Referer": "https://colab.research.google.com",  # Must match whitelisted origin
        "Content-Type": "application/json"
    }

    payload = {
        "model": "mistralai/mistral-7b-instruct",  # You can change this to any available OpenRouter model
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 300
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        response.raise_for_status()  # Raises HTTPError for 4xx or 5xx status

        data = response.json()

        if "choices" not in data or not data["choices"]:
            raise ValueError("No choices returned in API response.")

        return data["choices"][0]["message"]["content"].strip()

    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred: {http_err} - Status code: {response.status_code}")
        print("Response content:", response.text)
    except requests.exceptions.RequestException as req_err:
        print(f"Request error: {req_err}")
    except ValueError as ve:
        print(f"Data error: {ve}")
    except Exception as e:
        print(f"Unexpected error: {e}")

    return None

# ----------- PROMPT GENERATION -----------

def create_fund_description_prompt(row):
    return f"""
Write a concise description for a hypothetical alternatives fund named {row['PRODUCTNAME']}.
This fund follows a {row['STRATEGY']} strategy and is structured as a {row['VEHICLECATEGORY']} vehicle ({row['VEHICLETYPE']}).
It focuses on the {row['ASSETCLASS']} asset class and offers the {row['SHARECLASS']} share class.
It is marketed as part of the broader product line {row['PRODUCTCODE']} and may roll up to parent product {row['PARENTPRODUCTCODE']}.
Describe its primary themes, investor appeal, and product positioning in the alternative space.
"""

def create_strategy_prompt(row):
    return f"""
Summarize the investment strategy of the fund {row['PRODUCTNAME']}.
It applies a {row['STRATEGY']} approach within the {row['ASSETCLASS']} asset class.
The fund is offered through a {row['VEHICLECATEGORY']} vehicle type ({row['VEHICLETYPE']}) and is marketed using the {row['SHARECLASS']} share class structure.
Limit to 100 words and maintain an institutional tone.
"""

def create_manager_commentary_prompt(row):
    month_year = datetime.today().strftime("%B %Y")

    return f"""
Write a professional manager commentary for {row['PRODUCTNAME']} for {month_year}.
Include:
- Any challenges relevant to the {row['ASSETCLASS']} space
- Macro or market trends impacting {row['STRATEGY']} strategies
- A forward-looking outlook for investors in {row['SHARECLASS']} class funds
Use institutional language appropriate for alternative investment marketing.
"""

def generate_qualitative_paragraphs(df):
    """
    Generate qualitative descriptions, strategies, and manager commentary
    for each alternative fund in the provided DataFrame.

    Each row must contain the following columns:
    PRODUCTCODE, PRODUCTNAME, STRATEGY, VEHICLECATEGORY, VEHICLETYPE,
    ASSETCLASS, SHARECLASS, PERFORMANCEACCOUNT, REPRESENTATIVEACCOUNT,
    ISMARKETED, PARENTPRODUCTCODE

    Returns:
        pd.DataFrame with original fund data + qualitative text fields.
    """
    qualitative_rows = []

    # Use current month/year for commentary label
    month_year = datetime.today().strftime("%B %Y")

    for _, fund in df.iterrows():
        print(f"📝 Generating for {fund['PRODUCTNAME']}")

        # Generate prompts
        desc_prompt = create_fund_description_prompt(fund)
        strat_prompt = create_strategy_prompt(fund)
        comm_prompt = create_manager_commentary_prompt(fund)

        # Call GPT API or mocked function
        fund_description = fetch_data_from_api(desc_prompt)
        fund_strategy = fetch_data_from_api(strat_prompt)
        fund_commentary = fetch_data_from_api(comm_prompt)

        # Build enriched row
        qualitative_rows.append({
            **fund,
            "fund_description": fund_description,
            "fund_strategy": fund_strategy,
            f"fund_commentary_{month_year}": fund_commentary
        })

    return pd.DataFrame(qualitative_rows)

enriched_df = generate_qualitative_paragraphs(df_funds)

# Save to CSV (for export and Snowflake/other database usage)
enriched_df.to_csv("productmaster_table_synthetic_data.csv", index=False)

print("Synthetic data generated and saved as 'productmaster_table_synthetic_data.csv'")

"""##Potential Snowflake Implementation
This code is intended not only to demonstrate realistic data generation for academic or testing purposes but also to support end-to-end data pipelines where Snowflake acts as the target data warehouse. With minimal adjustments (e.g., schema renaming, batch control), this data can be used in:
* Report generation (e.g., Assette)
* Performance attribution systems
* ESG dashboards
* Fund analytics platforms

The code below shows a programmatic load using snowflake.connector in Python. Please see example.env to include your Snowflake database and API keys.
"""

import snowflake.connector

# Load credentials
load_dotenv()

sf_user = os.getenv("SNOWFLAKE_USER")
sf_password = os.getenv("SNOWFLAKE_PASSWORD")
sf_account = os.getenv("SNOWFLAKE_ACCOUNT")
sf_database = os.getenv("SNOWFLAKE_DATABASE")
sf_schema = os.getenv("SNOWFLAKE_SCHEMA")
sf_warehouse = os.getenv("SNOWFLAKE_WAREHOUSE")

# Connect to Snowflake
conn = snowflake.connector.connect(
    user=sf_user,
    password=sf_password,
    account=sf_account,
    warehouse=sf_warehouse,
    database=sf_database,
    schema=sf_schema
)

cursor = conn.cursor()

# Function to upload DataFrame
def append_to_snowflake(df, table_name):
    try:
        # Create temp CSV
        temp_csv = "/tmp/temp_fund_upload.csv"
        df.to_csv(temp_csv, index=False)

        # Create staging area in memory
        cursor.execute(f"PUT file://{temp_csv} @%{table_name} OVERWRITE = TRUE")

        # Copy from staged CSV to table
        columns = ",".join(df.columns)
        cursor.execute(f"""
            COPY INTO {table_name}
            FROM @%{table_name}
            FILE_FORMAT = (TYPE = CSV FIELD_OPTIONALLY_ENCLOSED_BY='"' SKIP_HEADER=1)
        """)

        print(f"✅ Data appended to {table_name} in Snowflake")

    except Exception as e:
        print("❌ Failed to upload data:", e)
    finally:
        cursor.close()
        conn.close()

# Example usage:
append_to_snowflake(df_funds, "PRODUCTMASTER")
